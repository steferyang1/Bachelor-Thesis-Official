{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e7268c-876d-4f26-a928-189cfb9adb8d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1796b-6495-4721-9484-de3b51076082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pyxdf\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.io import get_channel_type_constants\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992ab01-ade0-4b5e-8e36-4636aca66d7d",
   "metadata": {},
   "source": [
    "### Read xdf-file into MNE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b206f-4cc2-4548-b11d-06cd18ab565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_markerstream(stream):\n",
    "    srate = float(stream[\"info\"][\"nominal_srate\"][0])\n",
    "    n_chans = int(stream[\"info\"][\"channel_count\"][0])\n",
    "    return srate == 0 and n_chans == 1\n",
    "    \n",
    "def read_raw_xdf(\n",
    "    ## reads one condition of one participant experiment and turns it into an MNE raw object suitable for preprocessing.\n",
    "    #stream_ids = list [] of numbers that represent which streams contain the EEG signals\n",
    "    #marker_ids = list [] of numbers that represent which streams contain the markers\n",
    "    #fname = file name\n",
    "    fname,\n",
    "    stream_ids,\n",
    "    marker_ids=None,\n",
    "    prefix_markers=False,\n",
    "    fs_new=None,\n",
    "    *args,\n",
    "    **kwargs,\n",
    "):\n",
    "    if len(stream_ids) > 1 and fs_new is None:\n",
    "        raise ValueError(\"Argument `fs_new` required when reading multiple streams.\")\n",
    "        \n",
    "    streams, _ = pyxdf.load_xdf(fname)\n",
    "    streams = {stream[\"info\"][\"stream_id\"]: stream for stream in streams}\n",
    " \n",
    "    if all(_is_markerstream(streams[stream_id]) for stream_id in stream_ids):\n",
    "        raise RuntimeError(\n",
    "            \"Loading only marker streams is not supported, at least one stream must be a \"\n",
    "            \"regular stream.\"\n",
    "        )\n",
    "                                     \n",
    "    labels_all, types_all, units_all = [], [], []\n",
    "    for stream_id in stream_ids:\n",
    "        stream = streams[stream_id]\n",
    "    \n",
    "        n_chans = int(stream[\"info\"][\"channel_count\"][0])\n",
    "        labels, types, units = [], [], []\n",
    "        try:\n",
    "            for ch in stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]:\n",
    "                labels.append(str(ch[\"label\"][0]))\n",
    "                if ch[\"type\"] and ch[\"type\"][0].lower() in get_channel_type_constants(True):\n",
    "                    types.append(ch[\"type\"][0].lower())\n",
    "                else:\n",
    "                    types.append(\"misc\")\n",
    "                units.append(ch[\"unit\"][0] if ch[\"unit\"] else \"NA\")\n",
    "        except (TypeError, IndexError):  # no channel labels found\n",
    "            pass\n",
    "            \n",
    "        if not labels:\n",
    "            labels = [f\"{stream['info']['name'][0]}_{n}\" for n in range(n_chans)]   \n",
    "        if not units:\n",
    "            units = [\"NA\" for _ in range(n_chans)]\n",
    "        if not types:\n",
    "            types = [\"misc\" for _ in range(n_chans)]\n",
    "        labels_all.extend(labels)\n",
    "        types_all.extend(types)\n",
    "        units_all.extend(units)\n",
    "       \n",
    "    if fs_new is not None:\n",
    "        all_time_series, first_time = _resample_streams(streams, stream_ids, fs_new)\n",
    "        fs = fs_new\n",
    "    else:  # only possible if a single stream was selected\n",
    "        all_time_series = streams[stream_ids[0]][\"time_series\"]\n",
    "        first_time = streams[stream_ids[0]][\"time_stamps\"][0]\n",
    "        fs = float(np.array(stream[\"info\"][\"effective_srate\"]).item())\n",
    "    \n",
    "    info = mne.create_info(ch_names=labels_all, sfreq=fs, ch_types=types_all, verbose=False)\n",
    "    \n",
    "    microvolts = (\"microvolt\", \"microvolts\", \"µV\", \"?V\", \"uV\")\n",
    "    scale = np.array([1e-6 if u in microvolts else 1 for u in units_all])\n",
    "    all_time_series_scaled = (all_time_series * scale).T\n",
    "\n",
    "    raw = mne.io.RawArray(all_time_series_scaled, info, verbose=False)\n",
    "    raw._filenames = [fname]\n",
    "\n",
    "    # convert marker streams to annotations\n",
    "    for stream_id, stream in streams.items():\n",
    "        if marker_ids is not None and stream_id not in marker_ids:\n",
    "            continue\n",
    "        if not _is_markerstream(stream):\n",
    "            continue\n",
    "\n",
    "        onsets = stream[\"time_stamps\"] - first_time\n",
    "        prefix = f\"{stream_id}-\" if prefix_markers else \"\"\n",
    "    \n",
    "        # Create descriptions for the annotations\n",
    "        descriptions = [f\"{prefix}{item}\" for sub in stream[\"time_series\"] for item in sub]\n",
    "        \n",
    "        # Find the index where \"start_run\" appears\n",
    "        start_run_index = None\n",
    "        for i, description in enumerate(descriptions):\n",
    "            if description == \"start_run\":\n",
    "                start_run_index = i\n",
    "                break\n",
    "\n",
    "        # If \"start_run\" exists, start adding annotations from that point\n",
    "        true_descriptions = []\n",
    "        if start_run_index is not None:\n",
    "            for onset, description in zip(onsets[start_run_index:], descriptions[start_run_index:]):\n",
    "                # Add annotations starting from \"start_run\"\n",
    "                #print([description])\n",
    "                #print(onset)\n",
    "                raw.annotations.append(onset, [0], [description])\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3596d83-b145-408a-95e6-468c6bddfc99",
   "metadata": {},
   "source": [
    "### Visualize MNE object: channels + markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d78d5-6312-411b-b7ca-e2b689755ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(raw, j):\n",
    "    #1/j the number of data points you want to show:\n",
    "    \n",
    "    data = raw.get_data()\n",
    "    times = raw.times\n",
    "    times = times[:int(len(times)/j)]\n",
    "    #print(len(times))\n",
    "    #print(times)\n",
    "    \n",
    "    # Get the channel names from raw.info\n",
    "    channel_names = raw.info['ch_names']\n",
    "    print(\"channel_names\", channel_names)\n",
    "    fig, axs = plt.subplots(32, 2, figsize=(30, 200))\n",
    "    for i in range(64):\n",
    "        row = i // 2    # Determine the row index (0 to 20)\n",
    "        col = i % 2\n",
    "        data_plot = data[1+i]\n",
    "        data_plot = data_plot[:int(len(data_plot)/j)]\n",
    "        axs[row,col].plot(times,data_plot)\n",
    "        axs[row, col].set_title(channel_names[1+i]) \n",
    "        axs[row,col].set_xlabel('Times (s)')\n",
    "        axs[row,col].set_ylabel('EG Signal (uV)')\n",
    "        axs[row,col].set_xlim([times[0], times[-1]])\n",
    "        for onset in raw.annotations.onset:\n",
    "            axs[row,col].axvline(x=onset, color='r', linestyle='-', label=\"Annotation Onset\")\n",
    "    plt.subplots_adjust(hspace=0.5) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242baff-d823-4e82-92f1-ea8115bdf353",
   "metadata": {},
   "source": [
    "### bandpas filtering + epoching + downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2453ef2-f1b3-491e-a89d-d2943667cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(subject, data_dir, repo_dir):\n",
    "\n",
    "    condition_order = [[1, 2, 4, 3, 2, 3, 1, 4],  # row\n",
    "                    [2, 3, 1, 4, 1, 2, 4, 3],  # row, rotated by 1 to the left   \n",
    "                    [3, 4, 2, 1, 4, 1, 3, 2],  # row, rotated by 2 to the left\n",
    "                    [4, 1, 3, 2, 3, 4, 2, 1],  # row, rotated by 3 to the left\n",
    "                    [1, 2, 4, 3, 1, 2, 4, 3],\n",
    "                    [2, 3, 1, 4, 2, 3, 1, 4],\n",
    "                   ]\n",
    "    \n",
    "    #trial time\n",
    "    trial_time = 4.2\n",
    "    n_trials = 30\n",
    "    baseline = None\n",
    "    fs = 120\n",
    "    pr = 60\n",
    "    \n",
    "    l_freq = 6.00   #0.05\n",
    "    h_freq = 21.00  #25.05\n",
    "    \n",
    "    runs = [0,1]\n",
    "    \n",
    "    # Create output folder\n",
    "    if not os.path.exists(os.path.join(data_dir, \"derivatives\", subject)):\n",
    "        os.makedirs(os.path.join(data_dir, \"derivatives\", subject))\n",
    "    \n",
    "    i_person = int(subject[-2:])\n",
    "    conditions = condition_order[i_person-1]\n",
    "\n",
    "    done_conditions = []\n",
    "\n",
    "    for i_con in conditions:\n",
    "        eeg = []\n",
    "        labels = []\n",
    "        if i_con in done_conditions:\n",
    "            pass\n",
    "        else:\n",
    "            done_conditions.append(i_con)\n",
    "            condition_indexes = np.where(np.array(conditions) == i_con)\n",
    "            for i_run in runs:\n",
    "                \n",
    "                fn = os.path.join(data_dir, \"data\", f\"sub-{subject}\", \"ses-01\", \"eeg\",\n",
    "                                f\"sub-{subject}_ses-01_task-cvep_run-{condition_indexes[0][i_run]+1:03d}_eeg.xdf\")\n",
    "                    \n",
    "                # Load EEG\n",
    "                streams = pyxdf.resolve_streams(fn)\n",
    "                names = [stream[\"name\"] for stream in streams]\n",
    "                stream_id = streams[names.index(\"BioSemi\")][\"stream_id\"]\n",
    "                marker_id = streams[names.index(f\"KeyboardMarkerStream{int(condition_indexes[0][i_run])+1}\")][\"stream_id\"]\n",
    "                raw = read_raw_xdf(fn, stream_ids=[stream_id], marker_ids=[marker_id])\n",
    "                    \n",
    "                # Adjust marker channel data\n",
    "                #raw._data[0, :] -= np.median(raw._data[0, :])\n",
    "                #raw._data[0, :] = np.diff(np.concatenate((np.zeros(1), raw._data[0, :]))) > 0\n",
    "                    \n",
    "                # Read events\n",
    "                #events = mne.find_events(raw, stim_channel=\"Trig1\", verbose=False)\n",
    "                    \n",
    "                # Filtering (demeans and detrends)\n",
    "                raw.filter(l_freq=l_freq, h_freq=h_freq, fir_design='firwin')  # Common cVEP filtering\n",
    "                \n",
    "                visualize(raw, 10)\n",
    "    \n",
    "                #EPOCHING\n",
    "                #change events variable to only include markers for the trial (not the cue)\n",
    "                event_id = [f\"start_trial;trial={i_trial}\" for i_trial in range(n_trials)]\n",
    "                    \n",
    "                # Slicing\n",
    "                # N.B. add 0.5 sec pre and post trial to capture filtering artefacts of downsampling (removed later on)\n",
    "                # N.B. Use largest trial time (samples are cut away later)\n",
    "                epo = mne.Epochs(raw, events=None, event_id = event_id, tmin=-0.5, tmax=trial_time + 0.5, baseline=baseline, picks=\"eeg\",\n",
    "                                             preload=True, verbose=False)\n",
    "\n",
    "                #print(epo.times)  # array of time stamps (in seconds)\n",
    "                #print(f\"Shape: {epo.event_id}\")\n",
    "\n",
    "                #epo_data = epo.get_data()\n",
    "                #n_epochs = 3\n",
    "\n",
    "                #plt.figure(figsize=(12, 6))\n",
    "                #for i in range(n_epochs):\n",
    "                #    plt.plot(epo_data[i, 18, :], alpha=0.5, label=f\"Epoch {i+1}\")\n",
    "                \n",
    "                #plt.title(\"All Epochs - Channel 19\")\n",
    "                #plt.xlabel(\"Sample\")\n",
    "                #plt.ylabel(\"Amplitude (µV)\")  # Adjust unit if needed\n",
    "                #plt.grid(True)\n",
    "                #plt.tight_layout()\n",
    "                    \n",
    "                # Resampling\n",
    "                # N.B. Downsampling is done after slicing to maintain accurate stimulus timing\n",
    "                epo = epo.resample(sfreq=fs, verbose=False)\n",
    "                    \n",
    "                #print(epo.get_data(tmin=0, tmax=trial_time, copy=True).shape)\n",
    "                    \n",
    "                # Add EEG to database (trials channels samples)\n",
    "                eeg.append(epo.get_data(tmin=0, tmax=trial_time, copy=True))\n",
    "\n",
    "                # Load labels and conditions from marker stream\n",
    "                streams = pyxdf.load_xdf(fn)[0]\n",
    "                names = [stream[\"info\"][\"name\"][0] for stream in streams]\n",
    "                marker_stream = streams[names.index(f\"KeyboardMarkerStream{int(condition_indexes[0][i_run])+1}\")]\n",
    "                #print(str(marker_stream[\"time_series\"][0]).split(\";\")[1], \"_\", str(marker_stream[\"time_series\"][0]).split(\";\")[2])\n",
    "                labels.extend([int(str(marker[0]).split(\";\")[2].split(\"=\")[1]) for marker in marker_stream[\"time_series\"] if \n",
    "                                str(marker[0]).startswith(\"start_cue\") and str(marker[0]).split(\";\")[2].split(\"=\")[0] == \"target\"])\n",
    "\n",
    "                print(marker_stream[\"time_series\"][0])\n",
    "            \n",
    "            # Extract data\n",
    "            eeg = np.concatenate(eeg, axis=0).astype(\"float32\")  # trials channels samples\n",
    "            labels = np.array(labels).astype(\"uint8\")\n",
    "\n",
    "            # Select trials\n",
    "            X = eeg\n",
    "            y = labels\n",
    "\n",
    "            condition_to_codename = {1: \"m_sequence_shift_classes=30\", 2: \"m_sequence_shift_classes=5\", 3: \"m_sequence_shift_classes=5\", 4: \"m_sequence_shift_classes=30\"}\n",
    "            condition_to_codename_saving = {1: \"classes=30_bw\", 2: \"classes=5_grating\", 3: \"classes=5_bw\", 4: \"classes=30_grating\"}\n",
    "            # Load codes\n",
    "            fn = os.path.join(data_dir, \"data\", \"codes\", f\"{condition_to_codename[i_con]}.npz\")\n",
    "            V = np.load(fn)[\"codes_real\"]\n",
    "            print(\"V is: \",V.shape) \n",
    "            \n",
    "            print(condition_to_codename_saving[i_con])\n",
    "\n",
    "            V = np.repeat(V, int(fs / pr), axis=1).astype(\"uint8\")\n",
    "    \n",
    "            # Print summary\n",
    "            print(\"Condition:\", condition_to_codename[i_con])\n",
    "            print(\"\\tX:\", X.shape)\n",
    "            print(X)\n",
    "            print(\"\\ty:\", y.shape)\n",
    "            print(y)\n",
    "            print(\"\\tV:\", V.shape)\n",
    "            print(V)\n",
    "        \n",
    "            #Save data\n",
    "            np.savez(os.path.join(data_dir, \"derivatives\", subject, f\"{subject}_cvep_{condition_to_codename_saving[i_con]}.npz\"),\n",
    "                        X=X, y=y, V=V, fs=fs)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860f732-3355-4a7c-9336-83c9600409cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject 1\n",
    "subjects = [\n",
    "        \"05\"]\n",
    "for subject in subjects:\n",
    "    preprocess(subject, os.path.join(os.path.expanduser(\"~\"), \"ideaProjects\", \"programming\", \"BCI\", \"Thesis\", \"steven\", \"steven\"),\n",
    "             os.path.join(os.path.expanduser(\"~\"), \"ideaProjects\", \"programming\", \"BCI\", \"Thesis\", \"steven\", \"steven\", \"cvep_codes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f6e1d-71d2-41e9-a179-f5199e6cd3dd",
   "metadata": {},
   "source": [
    "# Improvements preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ce4d7-46c0-4301-9254-68ed9fb304d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(subject, data_dir, repo_dir):\n",
    "\n",
    "    condition_order = [[1, 2, 4, 3, 2, 3, 1, 4],  # row\n",
    "                    [2, 3, 1, 4, 1, 2, 4, 3],  # row, rotated by 1 to the left   \n",
    "                    [3, 4, 2, 1, 4, 1, 3, 2],  # row, rotated by 2 to the left\n",
    "                    [4, 1, 3, 2, 3, 4, 2, 1],  # row, rotated by 3 to the left\n",
    "                    [1, 2, 4, 3, 1, 2, 4, 3],\n",
    "                    [2, 3, 1, 4, 2, 3, 1, 4],\n",
    "                   ]\n",
    "    \n",
    "    #trial time\n",
    "    trial_time = 4.2\n",
    "    n_trials = 30\n",
    "    baseline = None\n",
    "    fs = 120\n",
    "    pr = 60\n",
    "    \n",
    "    l_freq = 6.00   #0.05\n",
    "    h_freq = 21.00  #25.05\n",
    "    \n",
    "    runs = [0,1]\n",
    "    \n",
    "    # Create output folder\n",
    "    if not os.path.exists(os.path.join(data_dir, \"derivatives\", subject)):\n",
    "        os.makedirs(os.path.join(data_dir, \"derivatives\", subject))\n",
    "    \n",
    "    i_person = int(subject[-2:])\n",
    "    conditions = condition_order[i_person-1]\n",
    "\n",
    "    done_conditions = []\n",
    "\n",
    "    for i_con in conditions:\n",
    "        eeg = []\n",
    "        labels = []\n",
    "        if i_con in done_conditions:\n",
    "            pass\n",
    "        else:\n",
    "            done_conditions.append(i_con)\n",
    "            condition_indexes = np.where(np.array(conditions) == i_con)\n",
    "            for i_run in runs:\n",
    "                \n",
    "                fn = os.path.join(data_dir, \"data\", f\"sub-{subject}\", \"ses-01\", \"eeg\",\n",
    "                                f\"sub-{subject}_ses-01_task-cvep_run-{condition_indexes[0][i_run]+1:03d}_eeg.xdf\")\n",
    "                    \n",
    "                # Load EEG\n",
    "                streams = pyxdf.resolve_streams(fn)\n",
    "                names = [stream[\"name\"] for stream in streams]\n",
    "                stream_id = streams[names.index(\"BioSemi\")][\"stream_id\"]\n",
    "                marker_id = streams[names.index(f\"KeyboardMarkerStream{int(condition_indexes[0][i_run])+1}\")][\"stream_id\"]\n",
    "                raw = read_raw_xdf(fn, stream_ids=[stream_id], marker_ids=[marker_id])\n",
    "                    \n",
    "                # Adjust marker channel data\n",
    "                #raw._data[0, :] -= np.median(raw._data[0, :])\n",
    "                #raw._data[0, :] = np.diff(np.concatenate((np.zeros(1), raw._data[0, :]))) > 0\n",
    "                    \n",
    "                # Read events\n",
    "                #events = mne.find_events(raw, stim_channel=\"Trig1\", verbose=False)\n",
    "                    \n",
    "                # Filtering (demeans and detrends)\n",
    "                raw.filter(l_freq=l_freq, h_freq=h_freq, fir_design='firwin')  # Common cVEP filtering\n",
    "                \n",
    "                visualize(raw, 10)\n",
    "    \n",
    "                #EPOCHING\n",
    "                #change events variable to only include markers for the trial (not the cue)\n",
    "                event_id = [f\"start_trial;trial={i_trial}\" for i_trial in range(n_trials)]\n",
    "                    \n",
    "                # Slicing\n",
    "                # N.B. add 0.5 sec pre and post trial to capture filtering artefacts of downsampling (removed later on)\n",
    "                # N.B. Use largest trial time (samples are cut away later)\n",
    "                epo = mne.Epochs(raw, events=None, event_id = event_id, tmin=-0.5, tmax=trial_time + 0.5, baseline=baseline, picks=\"eeg\",\n",
    "                                             preload=True, verbose=False)\n",
    "\n",
    "                #print(epo.times)  # array of time stamps (in seconds)\n",
    "                #print(f\"Shape: {epo.event_id}\")\n",
    "\n",
    "                #epo_data = epo.get_data()\n",
    "                #n_epochs = 3\n",
    "\n",
    "                #plt.figure(figsize=(12, 6))\n",
    "                #for i in range(n_epochs):\n",
    "                #    plt.plot(epo_data[i, 18, :], alpha=0.5, label=f\"Epoch {i+1}\")\n",
    "                \n",
    "                #plt.title(\"All Epochs - Channel 19\")\n",
    "                #plt.xlabel(\"Sample\")\n",
    "                #plt.ylabel(\"Amplitude (µV)\")  # Adjust unit if needed\n",
    "                #plt.grid(True)\n",
    "                #plt.tight_layout()\n",
    "                    \n",
    "                # Resampling\n",
    "                # N.B. Downsampling is done after slicing to maintain accurate stimulus timing\n",
    "                epo = epo.resample(sfreq=fs, verbose=False)\n",
    "                    \n",
    "                #print(epo.get_data(tmin=0, tmax=trial_time, copy=True).shape)\n",
    "                    \n",
    "                # Add EEG to database (trials channels samples)\n",
    "                eeg.append(epo.get_data(tmin=0, tmax=trial_time, copy=True))\n",
    "\n",
    "                # Load labels and conditions from marker stream\n",
    "                streams = pyxdf.load_xdf(fn)[0]\n",
    "                names = [stream[\"info\"][\"name\"][0] for stream in streams]\n",
    "                marker_stream = streams[names.index(f\"KeyboardMarkerStream{int(condition_indexes[0][i_run])+1}\")]\n",
    "                #print(str(marker_stream[\"time_series\"][0]).split(\";\")[1], \"_\", str(marker_stream[\"time_series\"][0]).split(\";\")[2])\n",
    "                labels.extend([int(str(marker[0]).split(\";\")[2].split(\"=\")[1]) for marker in marker_stream[\"time_series\"] if \n",
    "                                str(marker[0]).startswith(\"start_cue\") and str(marker[0]).split(\";\")[2].split(\"=\")[0] == \"target\"])\n",
    "\n",
    "                print(marker_stream[\"time_series\"][0])\n",
    "            \n",
    "            # Extract data\n",
    "            eeg = np.concatenate(eeg, axis=0).astype(\"float32\")  # trials channels samples\n",
    "            labels = np.array(labels).astype(\"uint8\")\n",
    "\n",
    "            # Select trials\n",
    "            X = eeg\n",
    "            y = labels\n",
    "\n",
    "            condition_to_codename = {1: \"m_sequence_shift_classes=30\", 2: \"m_sequence_shift_classes=5\", 3: \"m_sequence_shift_classes=5\", 4: \"m_sequence_shift_classes=30\"}\n",
    "            condition_to_codename_saving = {1: \"classes=30_bw\", 2: \"classes=5_grating\", 3: \"classes=5_bw\", 4: \"classes=30_grating\"}\n",
    "            # Load codes\n",
    "            fn = os.path.join(data_dir, \"data\", \"codes\", f\"{condition_to_codename[i_con]}.npz\")\n",
    "            V = np.load(fn)[\"codes_real\"]\n",
    "            print(\"V is: \",V.shape) \n",
    "            \n",
    "            print(condition_to_codename_saving[i_con])\n",
    "\n",
    "            V = np.repeat(V, int(fs / pr), axis=1).astype(\"uint8\")\n",
    "    \n",
    "            # Print summary\n",
    "            print(\"Condition:\", condition_to_codename[i_con])\n",
    "            print(\"\\tX:\", X.shape)\n",
    "            print(X)\n",
    "            print(\"\\ty:\", y.shape)\n",
    "            print(y)\n",
    "            print(\"\\tV:\", V.shape)\n",
    "            print(V)\n",
    "        \n",
    "            #Save data\n",
    "            np.savez(os.path.join(data_dir, \"derivatives\", subject, f\"{subject}_cvep_{condition_to_codename_saving[i_con]}.npz\"),\n",
    "                        X=X, y=y, V=V, fs=fs)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

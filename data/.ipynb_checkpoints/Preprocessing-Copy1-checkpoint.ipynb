{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e7268c-876d-4f26-a928-189cfb9adb8d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d1796b-6495-4721-9484-de3b51076082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pyxdf\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.io import get_channel_type_constants\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992ab01-ade0-4b5e-8e36-4636aca66d7d",
   "metadata": {},
   "source": [
    "### Read xdf-file into MNE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835b206f-4cc2-4548-b11d-06cd18ab565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_markerstream(stream):\n",
    "    srate = float(stream[\"info\"][\"nominal_srate\"][0])\n",
    "    n_chans = int(stream[\"info\"][\"channel_count\"][0])\n",
    "    return srate == 0 and n_chans == 1\n",
    "    \n",
    "def read_raw_xdf(\n",
    "    fname,\n",
    "    stream_ids,\n",
    "    marker_ids=None,\n",
    "    prefix_markers=False,\n",
    "    fs_new=None,\n",
    "    *args,\n",
    "    **kwargs,\n",
    "):\n",
    "    if len(stream_ids) > 1 and fs_new is None:\n",
    "        raise ValueError(\"Argument `fs_new` required when reading multiple streams.\")\n",
    "        \n",
    "    streams, _ = pyxdf.load_xdf(fname)\n",
    "    streams = {stream[\"info\"][\"stream_id\"]: stream for stream in streams}\n",
    " \n",
    "    if all(_is_markerstream(streams[stream_id]) for stream_id in stream_ids):\n",
    "        raise RuntimeError(\n",
    "            \"Loading only marker streams is not supported, at least one stream must be a \"\n",
    "            \"regular stream.\"\n",
    "        )\n",
    "                                     \n",
    "    labels_all, types_all, units_all = [], [], []\n",
    "    for stream_id in stream_ids:\n",
    "        stream = streams[stream_id]\n",
    "    \n",
    "        n_chans = int(stream[\"info\"][\"channel_count\"][0])\n",
    "        labels, types, units = [], [], []\n",
    "        try:\n",
    "            for ch in stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]:\n",
    "                labels.append(str(ch[\"label\"][0]))\n",
    "                if ch[\"type\"] and ch[\"type\"][0].lower() in get_channel_type_constants(True):\n",
    "                    types.append(ch[\"type\"][0].lower())\n",
    "                else:\n",
    "                    types.append(\"misc\")\n",
    "                units.append(ch[\"unit\"][0] if ch[\"unit\"] else \"NA\")\n",
    "        except (TypeError, IndexError):  # no channel labels found\n",
    "            pass\n",
    "            \n",
    "        if not labels:\n",
    "            labels = [f\"{stream['info']['name'][0]}_{n}\" for n in range(n_chans)]   \n",
    "        if not units:\n",
    "            units = [\"NA\" for _ in range(n_chans)]\n",
    "        if not types:\n",
    "            types = [\"misc\" for _ in range(n_chans)]\n",
    "        labels_all.extend(labels)\n",
    "        types_all.extend(types)\n",
    "        units_all.extend(units)\n",
    "       \n",
    "    if fs_new is not None:\n",
    "        all_time_series, first_time = _resample_streams(streams, stream_ids, fs_new)\n",
    "        fs = fs_new\n",
    "    else:  # only possible if a single stream was selected\n",
    "        all_time_series = streams[stream_ids[0]][\"time_series\"]\n",
    "        first_time = streams[stream_ids[0]][\"time_stamps\"][0]\n",
    "        fs = float(np.array(stream[\"info\"][\"effective_srate\"]).item())\n",
    "    \n",
    "    info = mne.create_info(ch_names=labels_all, sfreq=fs, ch_types=types_all, verbose=False)\n",
    "    \n",
    "    microvolts = (\"microvolt\", \"microvolts\", \"ÂµV\", \"?V\", \"uV\")\n",
    "    scale = np.array([1e-6 if u in microvolts else 1 for u in units_all])\n",
    "    all_time_series_scaled = (all_time_series * scale).T\n",
    "\n",
    "    raw = mne.io.RawArray(all_time_series_scaled, info, verbose=False)\n",
    "    raw._filenames = [fname]\n",
    "\n",
    "    # convert marker streams to annotations\n",
    "    for stream_id, stream in streams.items():\n",
    "        if marker_ids is not None and stream_id not in marker_ids:\n",
    "            continue\n",
    "        if not _is_markerstream(stream):\n",
    "            continue\n",
    "\n",
    "        onsets = stream[\"time_stamps\"] - first_time\n",
    "        prefix = f\"{stream_id}-\" if prefix_markers else \"\"\n",
    "    \n",
    "        # Create descriptions for the annotations\n",
    "        descriptions = [f\"{prefix}{item}\" for sub in stream[\"time_series\"] for item in sub]\n",
    "        \n",
    "        # Find the index where \"start_run\" appears\n",
    "        start_run_index = None\n",
    "        for i, description in enumerate(descriptions):\n",
    "            if description == \"start_run\":\n",
    "                start_run_index = i\n",
    "                break\n",
    "\n",
    "        # If \"start_run\" exists, start adding annotations from that point\n",
    "        true_descriptions = []\n",
    "        if start_run_index is not None:\n",
    "            for onset, description in zip(onsets[start_run_index:], descriptions[start_run_index:]):\n",
    "                # Add annotations starting from \"start_run\"\n",
    "                #print([description])\n",
    "                #print(onset)\n",
    "                raw.annotations.append(onset, [0], [description])\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3596d83-b145-408a-95e6-468c6bddfc99",
   "metadata": {},
   "source": [
    "### Visualize MNE object: channels + markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970d78d5-6312-411b-b7ca-e2b689755ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(raw, j):\n",
    "    #1/j the number of data points you want to show:\n",
    "    \n",
    "    data = raw.get_data()\n",
    "    times = raw.times\n",
    "    times = times[:int(len(times)/j)]\n",
    "    #print(len(times))\n",
    "    #print(times)\n",
    "    \n",
    "    # Get the channel names from raw.info\n",
    "    channel_names = raw.info['ch_names']\n",
    "    print(\"channel_names\", channel_names)\n",
    "    fig, axs = plt.subplots(32, 2, figsize=(30, 200))\n",
    "    for i in range(64):\n",
    "        row = i // 2    # Determine the row index (0 to 20)\n",
    "        col = i % 2\n",
    "        data_plot = data[1+i]\n",
    "        data_plot = data_plot[:int(len(data_plot)/j)]\n",
    "        axs[row,col].plot(times,data_plot)\n",
    "        axs[row, col].set_title(channel_names[1+i]) \n",
    "        axs[row,col].set_xlabel('Times (s)')\n",
    "        axs[row,col].set_ylabel('EG Signal (uV)')\n",
    "        axs[row,col].set_xlim([times[0], times[-1]])\n",
    "        for onset in raw.annotations.onset:\n",
    "            axs[row,col].axvline(x=onset, color='r', linestyle='-', label=\"Annotation Onset\")\n",
    "    plt.subplots_adjust(hspace=0.5) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242baff-d823-4e82-92f1-ea8115bdf353",
   "metadata": {},
   "source": [
    "### bandpas filtering + epoching + downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2453ef2-f1b3-491e-a89d-d2943667cdc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (2446025763.py, line 85)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 85\u001b[1;36m\u001b[0m\n\u001b[1;33m    V = np.load(fn)[\"codes_real\")\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "def preprocess(subject, data_dir, repo_dir):\n",
    "    \n",
    "    #trial time\n",
    "    trial_time = 4.2\n",
    "    baseline = None\n",
    "    fs = 120\n",
    "    pr = 60\n",
    "    \n",
    "    l_freq = 6.00   #0.05\n",
    "    h_freq = 21.00  #25.05\n",
    "    n_trials = 30\n",
    "    \n",
    "    # Create output folder\n",
    "    if not os.path.exists(os.path.join(data_dir, \"derivatives\", subject)):\n",
    "        os.makedirs(os.path.join(data_dir, \"derivatives\", subject))\n",
    "    \n",
    "    i_person = int(subject[3:])\n",
    "\n",
    "    eeg = dict()\n",
    "    labels = dict()\n",
    "    for i_run in range(8):\n",
    "                \n",
    "        fn = os.path.join(data_dir, \"data\", f\"sub-{subject}\", \"ses-01\", \"eeg\",\n",
    "                        f\"sub-{subject}_ses-01_task-cvep_run-{i_run+1:03d}_eeg.xdf\")\n",
    "\n",
    "        # Load labels and conditions from marker stream\n",
    "        streams = pyxdf.load_xdf(fn)[0]\n",
    "        names = [stream[\"info\"][\"name\"][0] for stream in streams]\n",
    "        marker_stream = streams[names.index(f\"KeyboardMarkerStream{i_run+1}\")]\n",
    "        y_ = [int(str(marker[0]).split(\";\")[2].split(\"=\")[1]) for marker in marker_stream[\"time_series\"] if \n",
    "                        str(marker[0]).startswith(\"start_cue\") and str(marker[0]).split(\";\")[2].split(\"=\")[0] == \"target\"]\n",
    "\n",
    "        tmp = marker_stream[\"time_series\"][0][0]\n",
    "        condition = tmp.split(\";\")[1]\n",
    "        if \"grating\" in tmp.split(\";\")[2]:\n",
    "            condition += \"_grating\"\n",
    "        else:\n",
    "            condition += \"_bw\"\n",
    "        print(condition)\n",
    "            \n",
    "        # Load EEG\n",
    "        streams = pyxdf.resolve_streams(fn)\n",
    "        names = [stream[\"name\"] for stream in streams]\n",
    "        stream_id = streams[names.index(\"BioSemi\")][\"stream_id\"]\n",
    "        marker_id = streams[names.index(f\"KeyboardMarkerStream{i_run+1}\")][\"stream_id\"]\n",
    "        raw = read_raw_xdf(fn, stream_ids=[stream_id], marker_ids=[marker_id])\n",
    "            \n",
    "        # Filtering (demeans and detrends)\n",
    "        raw.filter(l_freq=l_freq, h_freq=h_freq, fir_design='firwin', verbose=False)  # Common cVEP filtering\n",
    "\n",
    "        #EPOCHING\n",
    "        #change events variable to only include markers for the trial (not the cue)\n",
    "        event_id = [f\"start_trial;trial={i_trial}\" for i_trial in range(n_trials)]\n",
    "            \n",
    "        # Slicing\n",
    "        # N.B. add 0.5 sec pre and post trial to capture filtering artefacts of downsampling (removed later on)\n",
    "        # N.B. Use largest trial time (samples are cut away later)\n",
    "        epo = mne.Epochs(raw, events=None, event_id = event_id, tmin=-0.5, tmax=trial_time + 0.5, baseline=baseline, picks=\"eeg\",\n",
    "                                     preload=True, verbose=False)\n",
    "            \n",
    "        # Resampling\n",
    "        # N.B. Downsampling is done after slicing to maintain accurate stimulus timing\n",
    "        epo = epo.resample(sfreq=fs, verbose=False)\n",
    "            \n",
    "        #print(epo.get_data(tmin=0, tmax=trial_time, copy=True).shape)\n",
    "            \n",
    "        # Add EEG to database (trials channels samples)\n",
    "        X_ = epo.get_data(tmin=0, tmax=trial_time, copy=True)\n",
    "\n",
    "        if condition in eeg:\n",
    "            eeg[condition].append(X_)\n",
    "            labels[condition].extend(y_)\n",
    "        else:\n",
    "            eeg[condition] = [X_]\n",
    "            labels[condition] = y_\n",
    "\n",
    "    for condition in eeg.keys():\n",
    "        # Extract data\n",
    "        X = np.concatenate(eeg[condition], axis=0).astype(\"float32\")  # trials channels samples\n",
    "        y = np.array(labels[condition]).astype(\"uint8\")\n",
    "    \n",
    "        # Load codes\n",
    "        classes = condition.split('_')[0]\n",
    "        fn = os.path.join(data_dir, \"data\", \"codes\", f\"m_sequence_shift_{classes}.npz\")\n",
    "        V = np.load(fn)[\"codes_real\"]\n",
    "        V = np.repeat(V, int(fs / pr), axis=1).astype(\"uint8\")\n",
    "    \n",
    "        # Print summary\n",
    "        print(\"Condition:\", condition)\n",
    "        print(\"\\tX:\", X.shape)\n",
    "        print(\"\\ty:\", y.shape)\n",
    "        print(\"\\tV:\", V.shape)\n",
    "    \n",
    "        #Save data\n",
    "        np.savez(os.path.join(data_dir, \"derivatives\", subject, f\"{subject}_cvep_{condition}.npz\"),\n",
    "                 X=X, y=y, V=V, fs=fs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860f732-3355-4a7c-9336-83c9600409cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject 1\n",
    "subjects = [\n",
    "        \"01\", \"02\"]\n",
    "for subject in subjects:\n",
    "    preprocess(subject, os.path.join(os.path.expanduser(\"~\"), \"ideaProjects\", \"programming\", \"BCI\", \"Thesis\", \"steven\", \"steven\"),\n",
    "             os.path.join(os.path.expanduser(\"~\"), \"ideaProjects\", \"programming\", \"BCI\", \"Thesis\", \"steven\", \"steven\", \"cvep_codes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ce4d7-46c0-4301-9254-68ed9fb304d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835036f9-f733-4970-b783-b2453999d597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
